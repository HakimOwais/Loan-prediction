import os
import json
import time
import openai
from pymongo import MongoClient

# Import the MongoDB Atlas Vector Search store and OpenAIEmbeddings.
from langchain_openai import OpenAIEmbeddings
from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_core.prompts import PromptTemplate
from pymongo import MongoClient
from langchain.chains import RetrievalQA
from pathlib import Path
import sys
# # Adding the below path to avoid module not found error
PACKAGE_ROOT = Path(os.path.abspath(os.path.dirname(__file__))).parent
sys.path.append(str(PACKAGE_ROOT))
from src.components import client, llm, embeddings, TRANSACTION_COLLECTION
from chatbot.ingest import vector_store_transactions, ATLAS_VECTOR_SEARCH_INDEX_NAME
from chatbot.chain_setup import answer_question_from_context


# Define MongoDB filter
qa_retriever_transactions = vector_store_transactions.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.
Please make sure the answers you generate are from the context provided below, You can check yourself as well before passing the answer. make sure you provide the answers only and only from the context provided,.

{context}

Question: {question}
"""
PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

qa_transactions = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=qa_retriever_transactions,
    return_source_documents=True,
    chain_type_kwargs={"prompt": PROMPT},
)

def qa_transactions_driver(email, query):
    filter_condition = {"email": email}

    # Retrieve recommended documents using similarity search with the email filter applied
    results = vector_store_transactions.similarity_search(
        query, 
        k=3, 
        pre_filter={"email": {"$eq": email}}
    )
    
    # Print the retrieved documents to check the context
    print("Retrieved Documents:")
    for result in results:
        print(result)  # Print the individual results

    # Convert the results to the format expected by the chain (if needed, adjust structure)
    context = "\n".join([str(result) for result in results])  # Combine the retrieved documents into a single context

    # print("==========CONTEXT========")
    # print(context)
    # Now pass the results to the RetrievalQA chain along with the prompt to get an answer
    answer = answer_question_from_context(context=context, question=query)

    # Print the final answer generated by the chain
    print("Answer from QA Chain:")
    return answer.content

if __name__ == "__main__":
    print(qa_transactions_driver(email="rajesh.kumar@example.com", query="how much salary was credit to my acocunt"))
    # filter_condition2= {"email": "amit.sharma@example.com"}

    # retriever = vector_store_transactions.as_retriever(
    #     search_type="similarity_score_threshold",
    #     search_kwargs={"k": 1, "score_threshold": 0.1},
    #     filter = filter_condition2
    # )

    # # Ensure proper query is passed to invoke
    # result = retriever.invoke("how much salary was credit to my account")
    # print(result)
